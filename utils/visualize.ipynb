{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Import](#1-import)\n",
    "2. [필요한 정보 입력](#2-필요한-정보-입력)\n",
    "3. [Validation Dataset](#3-validation-dataset)   \n",
    "    3.1. [GT와 Pred 살펴보기](#31-gt와-pred-살펴보기)   \n",
    "        3.1.1 [색깔 가득 채우기](#311-색깔-가득-채우기)   \n",
    "        3.1.2 [점으로 테두리만 표현하기](#312-점으로-테두리만-표현하기)   \n",
    "4. [Test Dataset](#4-test-dataset)   \n",
    "    4.1. [Pred 살펴보기](#41-pred-살펴보기)   \n",
    "        4.1.1 [색깔 가득 채우기](#411-색깔-가득-채우기)   \n",
    "        4.1.2 [점으로 테두리만 표현하기](#412-점으로-테두리만-표현하기)   \n",
    "5. [CSV파일 시각화](#5-csv파일-시각화)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "os.chdir('/opt/ml/input/code/local')\n",
    "\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import XRayDataset, XRayInferenceDataset\n",
    "from visualize import label2rgb\n",
    "from inference import encode_mask_to_rle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 필요한 정보 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/opt/ml/input/data\"\n",
    "save_dir = \"/opt/ml/input/code/local/checkpoints/[test]Baseline1_1226\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colors\n",
    "PALETTE = [\n",
    "    (220, 20, 60),\n",
    "    (119, 11, 32),\n",
    "    (0, 0, 142),\n",
    "    (0, 0, 230),\n",
    "    (106, 0, 228),\n",
    "    (0, 60, 100),\n",
    "    (0, 80, 100),\n",
    "    (0, 0, 70),\n",
    "    (0, 0, 192),\n",
    "    (250, 170, 30),\n",
    "    (100, 170, 30),\n",
    "    (220, 220, 0),\n",
    "    (175, 116, 175),\n",
    "    (250, 0, 30),\n",
    "    (165, 42, 42),\n",
    "    (255, 77, 255),\n",
    "    (0, 226, 252),\n",
    "    (182, 182, 255),\n",
    "    (0, 82, 0),\n",
    "    (120, 166, 157),\n",
    "    (110, 76, 0),\n",
    "    (174, 57, 255),\n",
    "    (199, 100, 0),\n",
    "    (72, 0, 118),\n",
    "    (255, 179, 240),\n",
    "    (0, 125, 92),\n",
    "    (209, 0, 151),\n",
    "    (188, 208, 182),\n",
    "    (0, 220, 176),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rle_to_mask(rle, height, width):\n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    px = np.concatenate((starts//2048, ends//2048))\n",
    "    py = np.concatenate((starts%2048, ends%2048))\n",
    "    point = np.concatenate((np.expand_dims(px,1), np.expand_dims(py,1)), axis=1)\n",
    "    img = np.zeros(height * width, dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(height, width), point"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Resize(512, 512)\n",
    "dataset = XRayDataset(data_root, transforms=transform, split=\"val1\")\n",
    "model = torch.load(os.path.join(save_dir, \"best_model.pt\"))\n",
    "thr = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. GT와 Pred 살펴보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 색깔 가득 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_show(idx):\n",
    "    images, masks = dataset[idx]\n",
    "    images, masks = images.unsqueeze(0), masks.unsqueeze(0)\n",
    "    \n",
    "    image_name = \"/\".join(dataset.df.iloc[idx][\"filenames\"].split(\"/\")[-2:])\n",
    "    \n",
    "    outputs = model(images.cuda())[\"out\"]\n",
    "    output_h, output_w = outputs.size(-2), outputs.size(-1)\n",
    "    mask_h, mask_w = masks.size(-2), masks.size(-1)\n",
    "\n",
    "    # restore original size\n",
    "    if output_h != mask_h or output_w != mask_w:\n",
    "        outputs = F.interpolate(outputs, size=(mask_h, mask_w), mode=\"bilinear\")\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    outputs = (outputs > thr).detach().cpu()\n",
    "    \n",
    "    img = images[0].cpu().numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    img *= 255\n",
    "    img = img.astype(np.uint8)\n",
    "        \n",
    "    gt_mask = label2rgb(masks[0].cpu())\n",
    "    pred_mask = label2rgb(outputs[0].cpu())\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(24, 12))\n",
    "    show_imgs = [img, gt_mask, pred_mask]\n",
    "    show_titles = [image_name, \"GT\", \"Pred\"]\n",
    "    for i, (show_img, show_title) in enumerate(zip(show_imgs, show_titles)):\n",
    "        ax[i].imshow(show_img, cmap='gray')    # remove channel dimension\n",
    "        ax[i].set_title(show_title, fontsize=30)\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_show(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 점으로 테두리만 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_show(idx):\n",
    "    images, masks = dataset[idx]\n",
    "    images, masks = images.unsqueeze(0), masks.unsqueeze(0)\n",
    "    \n",
    "    image_name = \"/\".join(dataset.df.iloc[idx][\"filenames\"].split(\"/\")[-2:])\n",
    "    \n",
    "    outputs = model(images.cuda())[\"out\"]\n",
    "    output_h, output_w = outputs.size(-2), outputs.size(-1)\n",
    "    mask_h, mask_w = masks.size(-2), masks.size(-1)\n",
    "\n",
    "    # restore original size\n",
    "    if output_h != mask_h or output_w != mask_w:\n",
    "        outputs = F.interpolate(outputs, size=(mask_h, mask_w), mode=\"bilinear\")\n",
    "        images = F.interpolate(images, size=(mask_h, mask_w), mode=\"bilinear\")\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    outputs = (outputs > thr).detach().cpu().numpy()\n",
    "    \n",
    "    img = images[0].cpu().numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    img *= 255\n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    gts = []\n",
    "    for i, segm in enumerate(masks[0].cpu().numpy()):\n",
    "        rle = encode_mask_to_rle(segm)\n",
    "        _, point = decode_rle_to_mask(rle, height=2048, width=2048)\n",
    "        gts.append((i, point))\n",
    "    \n",
    "    preds = []\n",
    "    for i, segm in enumerate(outputs[0]):\n",
    "        rle = encode_mask_to_rle(segm)\n",
    "        _, point = decode_rle_to_mask(rle, height=2048, width=2048)\n",
    "        preds.append((i, point))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12))\n",
    "    show_imgs = [gts, preds]\n",
    "    show_titles = [image_name, \"Pred\"]\n",
    "    for i, (show_img, show_title) in enumerate(zip(show_imgs, show_titles)):\n",
    "        ax[i].imshow(img)\n",
    "        for cls in show_img:\n",
    "            c_id = cls[0]\n",
    "            x = cls[1][:, 1]\n",
    "            y = cls[1][:, 0]\n",
    "            ax[i].scatter(x, y, s=1, c=[np.array(PALETTE[c_id])/255])\n",
    "        ax[i].set_title(show_title, fontsize=30)\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_show(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Resize(512, 512)\n",
    "dataset = XRayInferenceDataset(data_root, transforms=transform)\n",
    "model = torch.load(os.path.join(save_dir, \"best_model.pt\"))\n",
    "thr = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Pred 살펴보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 색깔 가득 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_show(idx):\n",
    "    images, _ = dataset[idx]\n",
    "    images = images.unsqueeze(0)\n",
    "    \n",
    "    image_name = \"/\".join(dataset.df.iloc[idx][\"filenames\"].split(\"/\")[-2:])\n",
    "    \n",
    "    outputs = model(images.cuda())[\"out\"]\n",
    "    output_h, output_w = outputs.size(-2), outputs.size(-1)\n",
    "\n",
    "    # restore original size\n",
    "    if output_h != 2048 or output_w != 2048:\n",
    "        outputs = F.interpolate(outputs, size=(2048, 2048), mode=\"bilinear\")\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    outputs = (outputs > thr).detach().cpu()\n",
    "    \n",
    "    img = images[0].cpu().numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    img *= 255\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    pred_mask = label2rgb(outputs[0].cpu())\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12))\n",
    "    show_imgs = [img, pred_mask]\n",
    "    show_titles = [image_name, \"Pred\"]\n",
    "    for i, (show_img, show_title) in enumerate(zip(show_imgs, show_titles)):\n",
    "        ax[i].imshow(show_img, cmap='gray')    # remove channel dimension\n",
    "        ax[i].set_title(show_title, fontsize=30)\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_show(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 점으로 테두리만 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rle_to_mask(rle, height, width):\n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    px = np.concatenate((starts//2048, ends//2048))\n",
    "    py = np.concatenate((starts%2048, ends%2048))\n",
    "    point = np.concatenate((np.expand_dims(px,1), np.expand_dims(py,1)), axis=1)\n",
    "    img = np.zeros(height * width, dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(height, width), point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_show(idx):\n",
    "    images, _ = dataset[idx]\n",
    "    images = images.unsqueeze(0)\n",
    "    \n",
    "    image_name = \"/\".join(dataset.df.iloc[idx][\"filenames\"].split(\"/\")[-2:])\n",
    "    \n",
    "    outputs = model(images.cuda())[\"out\"]\n",
    "    output_h, output_w = outputs.size(-2), outputs.size(-1)\n",
    "\n",
    "    # restore original size\n",
    "    if output_h != 2048 or output_w != 2048:\n",
    "        outputs = F.interpolate(outputs, size=(2048, 2048), mode=\"bilinear\")\n",
    "        images = F.interpolate(images, size=(2048, 2048), mode=\"bilinear\")\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    outputs = (outputs > thr).detach().cpu().numpy()\n",
    "    \n",
    "    img = images[0].cpu().numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    img *= 255\n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    preds = []\n",
    "    for i, segm in enumerate(outputs[0]):\n",
    "        rle = encode_mask_to_rle(segm)\n",
    "        _, point = decode_rle_to_mask(rle, height=2048, width=2048)\n",
    "        preds.append((i, point))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(24, 12))\n",
    "    show_imgs = [preds]\n",
    "    show_titles = [image_name]\n",
    "    for i, (show_img, show_title) in enumerate(zip(show_imgs, show_titles)):\n",
    "        ax.imshow(img)\n",
    "        for cls in show_img:\n",
    "            c_id = cls[0]\n",
    "            x = cls[1][:, 1]\n",
    "            y = cls[1][:, 0]\n",
    "            ax.scatter(x, y, s=1, c=[np.array(PALETTE[c_id])/255])\n",
    "        ax.set_title(show_title, fontsize=30)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_show(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CSV파일 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/opt/ml/input/code/local/predictions/[test]Baseline1_1226/submission.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_show(idx):\n",
    "    rles = []\n",
    "    for i in range(29):\n",
    "        image_name, _, rle = df.iloc[idx*29+i]\n",
    "        rles.append(rle)\n",
    "        \n",
    "    for img_path in glob.glob(os.path.join(data_root, \"test/DCM/*/*.png\"), recursive=True):\n",
    "        if image_name in img_path:\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "    preds = []\n",
    "    for i, rle in enumerate(rles):\n",
    "        _, point = decode_rle_to_mask(rle, height=2048, width=2048)\n",
    "        preds.append((i, point))\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(24, 12))\n",
    "    show_imgs = [preds]\n",
    "    show_titles = [image_name]\n",
    "    for i, (show_img, show_title) in enumerate(zip(show_imgs, show_titles)):\n",
    "        ax.imshow(img)\n",
    "        for cls in show_img:\n",
    "            c_id = cls[0]\n",
    "            x = cls[1][:, 1]\n",
    "            y = cls[1][:, 0]\n",
    "            ax.scatter(x, y, s=1, c=[np.array(PALETTE[c_id])/255])\n",
    "        ax.set_title(show_title, fontsize=30)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_show(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
