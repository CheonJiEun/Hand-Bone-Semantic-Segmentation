{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b817f498-71af-4d7b-bb2f-5b81bdd23ada",
   "metadata": {},
   "source": [
    "## 확률값이 저장된 csv 파일 만들기 (csv -> parquet)\n",
    "확률값으로 앙상블하기 위해서 model을 불러와서 inference 과정을 다시 진행해야합니다.  \n",
    "모든 픽셀값을 저장하기엔 메모리 부족으로 threshold를 0.3으로 설정하여 해당 값을 초과한 확률값만 저장합니다.\n",
    "* 주의 : 모델을 학습시킬때의 동일한 Resize 크기로 inference를 진행해야합니다.\n",
    "* 파일을 읽는 시간 단축을 위해 format을 csv에서 parquet으로 저장하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052710d0-7f9c-4f62-94cc-ae2d3d924a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "\n",
    "if not os.path.exists('./ensemble_parquet'):\n",
    "    os.makedirs('./ensemble_parquet')\n",
    "\n",
    "# ============ TODO ===============\n",
    "\n",
    "model_file = '/opt/ml/input/code/checkpoints/[final]CJE/best_model.pt'  # 모델 weight 경로 설정\n",
    "save_parquet = './ensemble_parquet/'+ '[final]CJE.parquet' # 저장할 파일명 설정 (format : '.parquet')\n",
    "IMAGE_ROOT = \"/opt/ml/input/data/test/DCM\"  # test dataset 경로\n",
    "tf = A.Compose([     # Transform 설정 - 학습시 설정했던 Transform과 동일해야함\n",
    "        A.Resize(1024, 1024),\n",
    "])\n",
    "# ================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ac5d2-6f3a-4529-8c86-280d23863d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pngs = {\n",
    "    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n",
    "    for root, _dirs, files in os.walk(IMAGE_ROOT)\n",
    "    for fname in files\n",
    "    if os.path.splitext(fname)[1].lower() == \".png\"\n",
    "}\n",
    "print(len(pngs))  # 총 300개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a66d2-0a2d-4a93-8b9b-7eecac48b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n",
    "IND2CLASS = {v: k for k, v in CLASS2IND.items()}\n",
    "\n",
    "def encode_mask_to_rle(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    prob = []\n",
    "    runs = np.where((pixels[1:]>0) != (pixels[:-1]>0))[0] + 1   # 0이 아닌 연속적인 값의 시작 좌표 저장\n",
    "    runs[1::2] -= runs[::2]\n",
    "    for x, y in zip(runs[::2], runs[1::2]):\n",
    "        for i in range(y):\n",
    "            prob.append(round(pixels[x+i], 2))  # 확률값을 소수점 둘째자리까지 반올림한 값 저장\n",
    "    return ' '.join(str(x) for x in runs), ' '.join(str(x) for x in prob)\n",
    "\n",
    "class XRayInferenceDataset(Dataset):\n",
    "    def __init__(self, transforms=None):\n",
    "        _filenames = pngs\n",
    "        _filenames = np.array(sorted(_filenames))\n",
    "\n",
    "        self.filenames = _filenames\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image_name = self.filenames[item]\n",
    "        image_path = os.path.join(IMAGE_ROOT, image_name)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = image / 255.\n",
    "        # image = image.astype(\"float32\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            inputs = {\"image\": image}\n",
    "            result = self.transforms(**inputs)\n",
    "            image = result[\"image\"]\n",
    "\n",
    "        # to tenser will be done later\n",
    "        image = image.transpose(2, 0, 1)    # make channel first\n",
    "\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image, image_name\n",
    "\n",
    "def test(model, data_loader, thr=0.5):\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    rles = []\n",
    "    probs = []\n",
    "    filename_and_class = []\n",
    "    with torch.no_grad():\n",
    "        n_class = len(CLASSES)\n",
    "\n",
    "        for step, (images, image_names) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            images = images.cuda()\n",
    "            outputs = model(images)['out']\n",
    "\n",
    "            # restore original size\n",
    "            outputs = F.interpolate(outputs, size=(2048, 2048), mode=\"bilinear\")\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            outputs = np.where(outputs > 0.3, outputs, 0)   # threshold=0.3 초과면 확률값을, 아니라면 0으로 변환\n",
    "\n",
    "            for output, image_name in zip(outputs, image_names):\n",
    "                for c, segm in enumerate(output):\n",
    "                    rle, prob = encode_mask_to_rle(segm)   # rle 갯수에 맞는 확률값도 불러옴\n",
    "                    rles.append(rle)\n",
    "                    probs.append(prob)\n",
    "                    filename_and_class.append(f\"{IND2CLASS[c]}_{image_name}\")\n",
    "\n",
    "    return rles, probs, filename_and_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9c85d-5c8f-49fa-a6ac-62bc057924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XRayInferenceDataset(transforms=tf)\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afa4f7-6e74-4509-82ef-e324be7b09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(model_file)['model']\n",
    "from torchvision import models\n",
    "model = models.segmentation.fcn_resnet50(pretrained=True)\n",
    "model.classifier[4] = nn.Conv2d(512, 29, kernel_size=1)\n",
    "model.load_state_dict(torch.load(model_file)[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00ed7a-3c62-4f53-8b2a-3f89e5c2db61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rles, probs, filename_and_class = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f9f93-cf6a-42f5-8739-f10eef883397",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, filename = zip(*[x.split(\"_\") for x in filename_and_class])\n",
    "image_name = [os.path.basename(f) for f in filename]\n",
    "df = pd.DataFrame({\n",
    "    \"image_name\": image_name,\n",
    "    \"class\": classes,\n",
    "    \"rle\": rles,\n",
    "    \"prob\": probs,    # 확률값 저장 추가\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683cd14-566f-41cf-a52d-674f3209025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58944474-519f-4a59-8c23-050f609cca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"output.csv\", index=False)\n",
    "df.to_parquet(save_parquet, compression='gzip')   # 시간 단축을 위한 parquet(파케이) 포맷으로 저장 (읽을때 약 5배 시간단축)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08742bda-b3c1-48b0-b766-9d575090a380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
